{"cells":[{"cell_type":"markdown","metadata":{"id":"PbzBJ1m9FBBb"},"source":["\u003ccenter\u003e\u003ch1\u003e1-ab: SIFT \u0026 BoW\u003c/h1\u003e\u003c/center\u003e\n","\n","\u003ccenter\u003e\u003ch2\u003e\u003ca href=\"https://rdfia.github.io/\"\u003eCourse link\u003c/a\u003e\u003c/h2\u003e\u003c/center\u003e\n","\n","To keep your modifications in case you want to come back later to this colab, do *File -\u003e Save a copy in Drive*.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"NfnKy8NB8J5e"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2022-01-01 01:21:30--  http://webia.lip6.fr/~dancette/deep-learning/assets/TP1-2-data.zip\n","Resolving webia.lip6.fr (webia.lip6.fr)... 132.227.201.33\n","Connecting to webia.lip6.fr (webia.lip6.fr)|132.227.201.33|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 86446976 (82M) [application/zip]\n","Saving to: ‘TP1-2-data.zip.1’\n","\n","TP1-2-data.zip.1    100%[===================\u003e]  82.44M  25.5MB/s    in 3.2s    \n","\n","2022-01-01 01:21:34 (25.5 MB/s) - ‘TP1-2-data.zip.1’ saved [86446976/86446976]\n","\n","Archive:  TP1-2-data.zip\n","replace data/Scene/PARoffice/image_0091.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}],"source":["!wget http://webia.lip6.fr/~dancette/deep-learning/assets/TP1-2-data.zip\n","!unzip TP1-2-data.zip\n","\n","!wget https://raw.githubusercontent.com/rdfia/rdfia.github.io/master/code/1-ab/tools.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2vQ_LLdx8J5b"},"outputs":[],"source":["import matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline  \n","\n","import numpy as np\n","%run 'tools.py'\n","from os.path import join\n","\n","data_path = \"data\"\n","\n","import numpy as np\n","import scipy.stats as st\n","from sklearn.metrics.pairwise import euclidean_distances\n","from scipy.spatial import distance_matrix\n","from sklearn.preprocessing import normalize\n"]},{"cell_type":"markdown","metadata":{"id":"48x_ha7f8J5i"},"source":["# Part 1 : SIFT"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pxZOH3wD8J5i"},"outputs":[],"source":["# example images\n","I = read_grayscale(join(data_path, 'tools.tiff'))\n","I2 = read_grayscale(join(data_path, 'Scene/CALsuburb/image_0205.jpg'))\n","plt.imshow(I)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O8Xix9R_5nCK"},"outputs":[],"source":["print(len(I))\n","print(len(I[0]))\n","from math import *"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bhbk2DBY5rU0"},"outputs":[],"source":["Mx = 1/4*np.array([[-1, 0 ,1] ,[-2 ,0 ,2] , [-1, 0, 1]])\n","My = 1/4*np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])\n","hx = np.array([1, 2, 1])\n","hy = np.array([-1, 0, 1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJKLEzx88J5k"},"outputs":[],"source":["def compute_grad(I):\n","    Ix = conv_separable(I, hy, hx)\n","    Iy = conv_separable(I, hx, hy)\n","    return Ix, Iy\n","\n","# Example\n","Ix, Iy = compute_grad(I)\n","plt.imshow(Ix)\n","plt.colorbar()\n","plt.show()\n","plt.imshow(Iy)\n","plt.colorbar()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GtizX1JV8J5n"},"outputs":[],"source":["def compute_grad_mod_ori(I):\n","    Ix, Iy = compute_grad(I)\n","    Gn = np.sqrt(np.square(Ix) + np.square(Iy))\n","    Go = compute_grad_ori(Ix, Iy, Gn)\n","    return Gn, Go"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ktUrFzsk8J5p"},"outputs":[],"source":["Gn, Go = compute_grad_mod_ori(I)\n","plt.imshow(Gn)\n","plt.show()\n","plt.imshow(Go)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gOo5S8nu8J5r"},"outputs":[],"source":["def compute_histogram(g_n, g_o):\n","    hist = np.zeros((8))\n","    n = len(g_o)\n","    for i in range(len(g_o)):\n","      for j in range(len(g_o[0])):\n","        goij = g_o[i,j]\n","        if goij != -1:\n","          hist[goij] += g_n[i,j]\n","    return hist"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_YVNqP94tQWx"},"outputs":[],"source":["def gkern(kernlen, nsig):\n","    x = np.linspace(-nsig, nsig, kernlen+1)\n","    kern1d = np.diff(st.norm.cdf(x))\n","    kern2d = np.outer(kern1d, kern1d)\n","    return kern2d/kern2d.sum()\n","  \n","mask = 237*gkern(16, 0.5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eAsumzFI8J5u"},"outputs":[],"source":["def compute_sift_region(Gn, Go, mask=mask):\n","    t_min=.5\n","    t_max=.2\n","    with_l2 = True\n","\n","    patch_size = 16\n","    sift = np.zeros((128)) \n","\n","    if mask is not None:\n","        Gn = Gn * mask\n","    \n","    idx = 0\n","    for k in range(0, patch_size, 4):\n","        for l in range(0, patch_size, 4):\n","            hist = compute_histogram(Gn[l:l+4,k:k+4], Go[l:l+4,k:k+4])            \n","            sift[idx:idx+8] = hist\n","            idx += 8\n","\n","    norm = np.linalg.norm(sift, ord=2)\n","    # min thresholding on norm\n","    if norm \u003c= t_min:\n","        return np.zeros((128))\n","    # l2-normalization\n","    if with_l2:\n","        sift = sift / norm\n","    # max thresholding on values\n","    sift[sift \u003e= t_max] = t_max\n","    # l2-normalization\n","    if with_l2:\n","        norm = np.linalg.norm(sift, ord=2)\n","        sift = sift / norm\n","    return sift"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GESlu74v8J5w"},"outputs":[],"source":["# Example of viz of SIFTs\n","# set gausm to True to apply mask weighting of gradients\n","#display_sift_region(I,           compute_grad_mod_ori, compute_sift_region, x=200, y=78, gausm=False)\n","#display_sift_region(marche_im(), compute_grad_mod_ori, compute_sift_region, x=100, y=124, gausm=False)\n","#display_sift_region(marche_im(), compute_grad_mod_ori, compute_sift_region, x=125, y=100, gausm=False)\n","#display_sift_region(marche_im(), compute_grad_mod_ori, compute_sift_region, x=121, y=121, gausm=False)\n","display_sift_region(toy_im(),    compute_grad_mod_ori, compute_sift_region, x=95, y=95, gausm=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f68dU2zc8J5y"},"outputs":[],"source":["def compute_sift_image(I):\n","    x, y = dense_sampling(I)\n","    im = auto_padding(I)\n","    m = gaussian_mask()\n","    \n","    # Here, compute on the global image (norm, gradients)\n","    Gn, Go = compute_grad_mod_ori(I)\n","    sifts = np.zeros((len(x), len(y), 128))\n","    for i, xi in enumerate(x):\n","        for j, yj in enumerate(y):\n","            GnR = Gn[xi:xi+16, yj:yj+16]\n","            GoR = Go[xi:xi+16, yj:yj+16]\n","            sifts[i, j, :] = compute_sift_region(GnR, GoR, mask=None)\n","    return sifts"]},{"cell_type":"markdown","metadata":{"id":"yZukBC_K8J50"},"source":["# Compute SIFT"]},{"cell_type":"markdown","metadata":{"id":"yrzmLgQA8J50"},"source":["The computation can take several minutes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oGMbF2Sj9cus"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PlKBdt558J57"},"outputs":[],"source":["max_images_per_class = 10  # You can change this to None to compute the whole dataset (takes quite some time)\n","\n","save_path = \"/content/gdrive/My Drive/rdfia/\"\n","dir_sc = os.path.join(data_path, 'Scene')\n","dir_sift = os.path.join(save_path, 'sift')\n","inames, ilabls, cnames = load_dataset(dir_sc, images_per_class=max_images_per_class)\n","sifts_list_by_image = compute_load_sift_dataset(dir_sc, dir_sift, inames, compute_sift_image)"]},{"cell_type":"markdown","metadata":{"id":"OrHHH5PL8J54"},"source":["# Part 2 : Visual dictionnary"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9q755wymUvQQ"},"outputs":[],"source":["from sklearn.cluster import KMeans\n","\n","path_vdict = os.path.join(save_path, 'kmeans', 'vdict.npy')\n","os.makedirs(os.path.join(save_path, 'kmeans'), exist_ok=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w42e1Z6d8J6A"},"outputs":[],"source":["# Code here the `compute_visual_dict` function\n","def compute_visual_dict(sift, n_clusters=1000, n_init=1, verbose=1):\n","    # reorder data\n","    dim_sift = sift[0].shape[-1]\n","    sift = [s.reshape(-1, dim_sift) for s in sift]\n","    sift = np.concatenate(sift, axis=0)\n","    # remove zero vectors\n","    keep = ~np.all(sift==0, axis=1)\n","    sift = sift[keep]\n","    # randomly pick sift\n","    ids, _ = compute_split(sift.shape[0], pc=0.05)\n","    sift = sift[ids]\n","\n","    kmeans = KMeans(n_clusters=n_clusters, n_init=n_init, verbose=verbose).fit(sift)\n","    vdict = kmeans.cluster_centers_\n","    vdict.append(np.zeros((128)))\n","\n","    return vdict\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"97qG503C8J6C"},"outputs":[],"source":["# Run the visual dict computation (saved the first time)\n","vdict = compute_or_load_vdict(dir_sc, dir_sift, inames, compute_sift_image, path_vdict, compute_visual_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pcpOdcs58J6F"},"outputs":[],"source":["# Study of the dict\n","\n","# choose random images\n","indexes = np.random.randint(0, len(inames), 30)\n","sifts = [sifts_list_by_image[i] for i in indexes]\n","chosen_inames = [inames[i] for i in indexes]\n","\n","regions, sifts = get_regions_and_sifts(dir_sc, chosen_inames, sifts) # Compute SIFT and regions from 30 random images\n","display_images(regions[np.random.choice(len(regions), 100)]) # Show 100 random regions\n","\n","centers = list(range(20))\n","for center in centers:\n","  center_vect = vdict[center]\n","  dist = ((sifts - center_vect)**2).sum(axis=1)\n","  # get best 100\n","  top100 = dist.argsort()[:100]\n","  top100_regions = regions[top100]\n","  display_images(top100_regions) # Show 100 random regions\n","  "]},{"cell_type":"markdown","metadata":{"id":"5FV1iss68J6H"},"source":["# Partie 3 : BoW"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"5-h4r-FH8J6I"},"outputs":[],"source":["def compute_feats(vdict, image_sifts):\n","    # flatten sifts\n","    sifts = image_sifts.reshape(-1, 128)  # (N, 128)\n","    feats = np.zeros(vdict.shape[0])\n","\n","    for sift in sifts : \n","      ind_min = np.argmin(distance_matrix(vdict, sift.reshape(1,128)))\n","      feats[ind_min] += 1\n","\n","    feats = feats.reshape(1,-1)\n","    feats = normalize(feats, norm='l2')\n","    feats = feats[0]\n","\n","    return feats"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Is9sv-RM8J6K"},"outputs":[],"source":["# Visualize your BoW on an image\n","iname = inames[0]\n","ipath = os.path.join(dir_sc, iname)\n","im = read_grayscale(ipath)\n","sifts = compute_sift_image(im)\n","sifts = (sifts * 255).astype('uint8')\n","regions = compute_regions(im)\n","feats = compute_feats(vdict, sifts)\n","\n","display_vdregions_image(im, vdict, sifts, feats, vdregions=None) # if you have vdregions, add it as input here"]},{"cell_type":"markdown","metadata":{"id":"xEmnYyZdE_vH"},"source":["1) hx = (1, 2, 1) hy = (-1, 0, 1)\n","2) Permet parfois de faire moins d'étapes de calcul ?\n","3) Accorder plus d'importance aux gradients au centre du patch. Pour mieux différencier les types de sifts ? Image smoothing ?\n","4)  \n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ihpkyASZsyR_"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Copie de 1-ab_ Sift \u0026 Bow.ipynb","provenance":[{"file_id":"1jL8yy91z6RI0JJIxMQi6Odkh3uMeb7-H","timestamp":1632924670092},{"file_id":"1oiNJQ5SNZpeV-029XvJs9L2HRsG0AHxI","timestamp":1602072598000}],"version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":0}